{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHkjq6ostfOb",
        "outputId": "a51a1f36-ed1c-4bf7-831e-3cf9538546c7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-De_vbVBsgwc"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# import pandas as pd\n",
        "# import time\n",
        "# import openai\n",
        "\n",
        "# # Step 1: Set up your Cohere API account\n",
        "# deployment_name = \"reviews_analysis_bot\"\n",
        "# openai.api_type = \"azure\"\n",
        "# openai.api_key = \"548fdf1f982446dab8502f4c9c4b170f\"\n",
        "# openai.api_base = \"https://finetune-bot.openai.azure.com/\"  #instance on azure\n",
        "# openai.api_version = \"2022-12-01\"\n",
        "# API_KEY = \"548fdf1f982446dab8502f4c9c4b170f\"\n",
        "\n",
        "# # Step 2: Use the Cohere API for text completion\n",
        "# def complete_text(prompt):\n",
        "#     url = \"https://api.cohere.ai/completion/v1/completion\"\n",
        "#     headers = {\n",
        "#         \"Authorization\": f\"Bearer {openai.API_KEY}\",\n",
        "#         \"Content-Type\": \"application/json\"\n",
        "#     }\n",
        "#     data = {\n",
        "#         \"prompt\": prompt,\n",
        "#         \"max_tokens\": 100,\n",
        "#         \"temperature\": 0.7\n",
        "#     }\n",
        "#     response = requests.post(url, headers=headers, json=data, verify=False)\n",
        "#     response_json = response.json()\n",
        "#     return response_json[\"choices\"][0][\"text\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Step 3: Extract new diseases and symptoms\n",
        "\n",
        "# def extract_new_diseases_symptoms(generated_text, existing_data):\n",
        "\n",
        "#     # Extract the newly suggested diseases and symptoms\n",
        "\n",
        "#     new_data = generated_text.split(\"[NEW DATA]\")[-1].strip()\n",
        "\n",
        "\n",
        "\n",
        "#     # Split the new data into lines\n",
        "\n",
        "#     new_lines = new_data.split(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "#     # Process each line to extract disease and symptoms\n",
        "\n",
        "#     new_diseases = []\n",
        "\n",
        "#     new_symptoms = []\n",
        "\n",
        "#     for line in new_lines:\n",
        "\n",
        "#         line = line.strip()\n",
        "\n",
        "#         if line:\n",
        "\n",
        "#             parts = line.split(\":\")\n",
        "\n",
        "#             if len(parts) == 2:\n",
        "\n",
        "#                 disease = parts[0].strip()\n",
        "\n",
        "#                 symptoms = [s.strip() for s in parts[1].split(\",\") if s.strip()]\n",
        "\n",
        "#                 new_diseases.append(disease)\n",
        "\n",
        "#                 new_symptoms.append(symptoms)\n",
        "\n",
        "\n",
        "\n",
        "#     # Compare with existing dataset and find new entries\n",
        "\n",
        "#     new_diseases = [d for d in new_diseases if d not in existing_data[\"Disease\"]]\n",
        "\n",
        "#     new_symptoms = [s for s in new_symptoms if s not in existing_data[\"Symptom_1\":\"Symptom_17\"].values.tolist()]\n",
        "\n",
        "\n",
        "\n",
        "#     return new_diseases, new_symptoms\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Step 4: Generate new data automatically\n",
        "\n",
        "# def generate_new_data(existing_data, num_entries=10):\n",
        "\n",
        "#     new_diseases = []\n",
        "\n",
        "#     new_symptoms = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     while len(new_diseases) < num_entries:\n",
        "\n",
        "#         prompt = \"Given the following diseases and symptoms:\\n\\n\" + existing_data.to_string(index=False)\n",
        "\n",
        "#         generated_text = complete_text(prompt)\n",
        "\n",
        "#         extracted_diseases, extracted_symptoms = extract_new_diseases_symptoms(generated_text, existing_data)\n",
        "\n",
        "#         new_diseases.extend(extracted_diseases)\n",
        "\n",
        "#         new_symptoms.extend(extracted_symptoms)\n",
        "\n",
        "\n",
        "\n",
        "#     return new_diseases[:num_entries], new_symptoms[:num_entries]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Step 5: Load existing dataset\n",
        "\n",
        "# def load_existing_data(csv_path):\n",
        "\n",
        "#     existing_data = pd.read_csv(csv_path)\n",
        "\n",
        "#     return existing_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Step 6: Print new data\n",
        "\n",
        "# def print_new_data(new_diseases, new_symptoms):\n",
        "\n",
        "#     print(\"New Diseases and Symptoms:\")\n",
        "\n",
        "#     for disease, symptoms in zip(new_diseases, new_symptoms):\n",
        "\n",
        "#         print(\"Disease:\", disease)\n",
        "\n",
        "#         print(\"Symptoms:\", \", \".join(symptoms))\n",
        "\n",
        "#         print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Main execution\n",
        "\n",
        "# def main():\n",
        "\n",
        "#     # Load existing dataset\n",
        "\n",
        "#     csv_path = \"/content/drive/MyDrive/Colab Notebooks/DataSet/dataset.csv\"\n",
        "\n",
        "#     existing_data = load_existing_data(csv_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     # Generate new data\n",
        "\n",
        "#     new_diseases, new_symptoms = generate_new_data(existing_data, num_entries=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     # Print new data\n",
        "\n",
        "#     print_new_data(new_diseases, new_symptoms)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "HVhCCr6l-9HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-ai-textanalytics\n"
      ],
      "metadata": {
        "id": "Y0DokcPH_l1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2d9c7c-bdf2-4c6e-ad7f-daa708f00ad3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-ai-textanalytics in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-textanalytics) (1.28.0)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-textanalytics) (1.1.28)\n",
            "Requirement already satisfied: isodate<1.0.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-textanalytics) (0.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-ai-textanalytics) (4.7.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.27.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-core\n"
      ],
      "metadata": {
        "id": "ySUPy3WI_2kW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48f2092-2187-4243-aa48-9f444792b4dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure-core in /usr/local/lib/python3.10/dist-packages (1.28.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from azure-core) (2.27.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-core) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure.cognitiveservices.language.textanalytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlEUphr4CR8O",
        "outputId": "6d459e92-373a-4687-dff0-6761d18b9aea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: azure.cognitiveservices.language.textanalytics in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: msrest>=0.6.21 in /usr/local/lib/python3.10/dist-packages (from azure.cognitiveservices.language.textanalytics) (0.7.1)\n",
            "Requirement already satisfied: azure-common~=1.1 in /usr/local/lib/python3.10/dist-packages (from azure.cognitiveservices.language.textanalytics) (1.1.28)\n",
            "Requirement already satisfied: azure-mgmt-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from azure.cognitiveservices.language.textanalytics) (1.4.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from azure-mgmt-core<2.0.0,>=1.2.0->azure.cognitiveservices.language.textanalytics) (1.28.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (2023.5.7)\n",
            "Requirement already satisfied: isodate>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (1.3.1)\n",
            "Requirement already satisfied: requests~=2.16 in /usr/local/lib/python3.10/dist-packages (from msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (2.27.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure.cognitiveservices.language.textanalytics) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.2->azure-mgmt-core<2.0.0,>=1.2.0->azure.cognitiveservices.language.textanalytics) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.16->msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (1.26.16)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests~=2.16->msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.16->msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (3.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure.cognitiveservices.language.textanalytics) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "# Step 1: Set up Azure environment and resources\n",
        "# Step 2: Obtain the Azure API key\n",
        "azure_api_key = \"YOUR_AZURE_API_KEY\"\n",
        "# Step 3: Install required dependencies and libraries\n",
        "# Step 4: Set up authentication and connection\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "azure_credentials = AzureKeyCredential(azure_api_key)\n",
        "azure_endpoint = \"YOUR_AZURE_ENDPOINT\"\n",
        "# Step 6: Implement chatbot logic\n",
        "def chatbot_response(user_input):\n",
        "    # Send user input to the GPT-3.5-turbo model using OpenAI API\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"davinci\",\n",
        "        prompt=user_input,\n",
        "        max_tokens=100,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "# Step 5: Define the chatbot interface\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_response,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Chatbot\",\n",
        "    description=\"Enter a prompt to chat with the chatbot.\",\n",
        "    theme=\"default\"\n",
        ")\n",
        "# Step 7: Test and iterate\n",
        "# Step 8: Deploy and monitor\n",
        "# Step 9: Maintain and update\n",
        "# Main execution\n",
        "def main():\n",
        "    # User interaction loop\n",
        "    while True:\n",
        "        user_input = input(\"User: \")\n",
        "        # Call chatbot logic to get response\n",
        "        chatbot_responses = chatbot_response(user_input)\n",
        "        # Display chatbot response\n",
        "        print(\"Chatbot:\", chatbot_responses)\n",
        "        # Perform any additional processing or actions based on the response\n",
        "        # Exit condition\n",
        "        if user_input.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "X-4gCJRLtknl",
        "outputId": "7b4735b9-54a0-4dca-bad9-be5e6340fa0d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: What is Cricket?\n",
            "Chatbot: Cricket is the most popular game in the world. The most popular form of the sport is played between two teams of 11 players each. Each team takes it in turn to bat, meaning one team fields while the other bats. The team that bats tries to score as many runs as possible and when they are all out, the teams change roles.\n",
            "\n",
            "The bowler bowls the ball to the batsman who tries to defend the wicket by hitting the ball with a bat.\n",
            "User: Hey\n",
            "Chatbot: , I know you can't hear me, but I'm going to talk to you anyway. I'm going to tell you about the first time I saw you.\"\n",
            "\n",
            "She could see him now, a picture in her mind. She could hear his voice, filling her ears. She could see his face, the way he looked when he talked.\n",
            "\n",
            "\"It was a couple of weeks after you started, and you were sitting at your desk. I was in the back room doing something\n",
            "User: Please walk me through the context\n",
            "Chatbot: .” I was really polite. I didn’t want to make him feel cornered. He said, “I just think you should be more careful about what you put out there.” That was kind of the end of the conversation.\n",
            "\n",
            "He was really nice about it, so I can’t complain about that, but after that conversation, I was like, “Wow, I guess I really do have to be careful about what I’m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-d61ab768999e>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-d61ab768999e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# User interaction loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Call chatbot logic to get response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mchatbot_responses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatbot_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def generate_response(chatbot):\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=chatbot,\n",
        "        max_tokens=100,\n",
        "        temperature=0.7,\n",
        "        top_p=1.0,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "def chatbot_interface(chatbot):\n",
        "    response = generate_response(chatbot)\n",
        "    return response\n",
        "iface = gr.Interface(\n",
        "    fn=chatbot_interface,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Chatbot\",\n",
        "    description=\"Type your message to chat with the bot!\"\n",
        ")\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "j4JHusUUKHmn",
        "outputId": "7744e3cf-dc12-4765-f338-8b2c9cd6ef7e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bVCnvpPbKut-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}